{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "base_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Base Model\n",
        "---\n",
        "This model is taken from the Recursive Recurrent Nets with Attention Modeling for OCR in the Wild paper by Lee et al. In their paper, Lee construct a recursive recurrent neural network with attention modeling. For our project we want to first understand this model architecture, and then try to improve upon it. Later we will provide an ethical analysis for OCR technology."
      ],
      "metadata": {
        "id": "Cli5G9-3gpLU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ChU11qDfgT7j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the paper, the base model: \n",
        "> has 8 convolutional layer with 64, 64, 128, 128, 256, 256, 512 and 512 channels, and each convolutional layer uses kernel with a 3 × 3 spatial extent. Convo- lutions are performed with stride 1, zero padding, and ReLU activation function. 2 × 2 max pooling follows the second, fourth, and sixth convolutional layers. The two fully con- nected layers have 4096 units. The input is a resized 32 × 100 gray scale image."
      ],
      "metadata": {
        "id": "W-uVRoffh6k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_classes = len(string.printable)"
      ],
      "metadata": {
        "id": "-s1sWiuuk1tr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'base_cnn_model' in locals():\n",
        "  del base_cnn_model\n",
        "\n",
        "input_shape = (100, 32, 1)\n",
        "\n",
        "base_cnn_model = keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape = input_shape),\n",
        "     layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", name = \"cov_layer1\"),\n",
        "     layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", name = \"cov_layer2\"),\n",
        "     layers.MaxPooling2D((2, 2), name = \"pool1\"),\n",
        "     layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", name = \"cov_layer3\"),\n",
        "     layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", name = \"cov_layer4\"),\n",
        "     layers.MaxPooling2D((2, 2), name = \"pool2\"),\n",
        "     layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", name = \"cov_layer5\"),\n",
        "     layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", name = \"cov_layer6\"),\n",
        "     layers.MaxPooling2D((2, 2), name = \"pool3\"),\n",
        "     layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", name = \"cov_layer7\"),\n",
        "     layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", name = \"cov_layer8\"),\n",
        "     layers.Flatten(),\n",
        "     layers.Dense(units = 4096),\n",
        "     layers.Dense(units = 4096),\n",
        "     layers.Dense(softmax_classes, activation = \"softmax\")\n",
        "    ],\n",
        "    name = 'base_cnn_model'\n",
        ")\n",
        "\n",
        "base_cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x46pGurygnw7",
        "outputId": "1a9f54eb-73b8-4cd8-8fcd-d0c137334989"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"base_cnn_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " cov_layer1 (Conv2D)         (None, 100, 32, 64)       640       \n",
            "                                                                 \n",
            " cov_layer2 (Conv2D)         (None, 100, 32, 64)       36928     \n",
            "                                                                 \n",
            " pool1 (MaxPooling2D)        (None, 50, 16, 64)        0         \n",
            "                                                                 \n",
            " cov_layer3 (Conv2D)         (None, 50, 16, 64)        36928     \n",
            "                                                                 \n",
            " cov_layer4 (Conv2D)         (None, 50, 16, 64)        36928     \n",
            "                                                                 \n",
            " pool2 (MaxPooling2D)        (None, 25, 8, 64)         0         \n",
            "                                                                 \n",
            " cov_layer5 (Conv2D)         (None, 25, 8, 64)         36928     \n",
            "                                                                 \n",
            " cov_layer6 (Conv2D)         (None, 25, 8, 64)         36928     \n",
            "                                                                 \n",
            " pool3 (MaxPooling2D)        (None, 12, 4, 64)         0         \n",
            "                                                                 \n",
            " cov_layer7 (Conv2D)         (None, 12, 4, 64)         36928     \n",
            "                                                                 \n",
            " cov_layer8 (Conv2D)         (None, 12, 4, 64)         36928     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 4096)              12587008  \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 100)               409700    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,037,156\n",
            "Trainable params: 30,037,156\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lee et al continue saying:\n",
        "> For the character-level language modeling, we use RNNs with 1024 hidden units equipped with hyperbolic tangent activation function.\n",
        "\n",
        "I believe it is within the RNN that the activation layer is called, not the CNN like I initially believed."
      ],
      "metadata": {
        "id": "5lAd0MXFjaYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.dense_attention import Attention\n",
        "if 'base_rnn_model' in locals():\n",
        "  del base_rnn_model\n",
        "\n",
        "input_shape = (100, 32, 1)\n",
        "\n",
        "base_rnn_model = keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape = input_shape),\n",
        "     layers.Dense(units = 1024, activation = 'tanh', name='rnn_layer1'),\n",
        "     layers.Attention(['rnn_layer1']),\n",
        "     layers.Dense(units = 1024, activation = 'tanh'),\n",
        "     layers.Dense(softmax_classes, activation = \"softmax\")\n",
        "    ],\n",
        "    name = 'base_rnn_model'\n",
        ")\n",
        "\n",
        "base_rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "Al3Tg68qi0Ja",
        "outputId": "b70c31a9-5674-4e90-9ca7-8e00db12d276"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e51f628c22e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m      \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     ],\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'base_rnn_model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/dense_attention.py\u001b[0m in \u001b[0;36m_validate_call_args\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m       raise ValueError(\n\u001b[0;32m--> 193\u001b[0;31m           \u001b[0;34mf'{class_name} layer must be called on a list of inputs, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m           \u001b[0;34m'namely [query, value] or [query, value, key]. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           f'Received: {inputs}.')\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"attention_1\" (type Attention).\n\nAttention layer must be called on a list of inputs, namely [query, value] or [query, value, key]. Received: Tensor(\"Placeholder:0\", shape=(None, 100, 32, 1024), dtype=float32).\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 100, 32, 1024), dtype=float32)\n  • mask=None\n  • training=None\n  • return_attention_scores=False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JhPgOZMVkw1P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}