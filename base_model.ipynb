{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cli5G9-3gpLU"
   },
   "source": [
    "# Base Model\n",
    "---\n",
    "This model is taken from the Recursive Recurrent Nets with Attention Modeling for OCR in the Wild paper by Lee et al. In their paper, Lee construct a recursive recurrent neural network with attention modeling. For our project we want to first understand this model architecture, and then try to improve upon it. Later we will provide an ethical analysis for OCR technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ChU11qDfgT7j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-uVRoffh6k0"
   },
   "source": [
    "From the paper, the base model: \n",
    "> has 8 convolutional layer with 64, 64, 128, 128, 256, 256, 512 and 512 channels, and each convolutional layer uses kernel with a 3 × 3 spatial extent. Convo- lutions are performed with stride 1, zero padding, and ReLU activation function. 2 × 2 max pooling follows the second, fourth, and sixth convolutional layers. The two fully con- nected layers have 4096 units. The input is a resized 32 × 100 gray scale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-s1sWiuuk1tr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax_classes = len(string.printable)\n",
    "print(string.printable)\n",
    "\n",
    "eow = torch.zeros(size=(len(string.printable) + 1,))\n",
    "eow[len(string.printable)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x46pGurygnw7",
    "outputId": "1a9f54eb-73b8-4cd8-8fcd-d0c137334989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;;;;;;;;;;;;;;;;;;;;;;"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from base_model import BaseModel\n",
    "base_cnn_model = BaseModel(eow=eow).to(device)\n",
    "\n",
    "x = torch.rand(1, 1, 32, 100).to(device)\n",
    "x = base_cnn_model(x)\n",
    "\n",
    "preds = torch.argmax(x[0].T, dim=1).tolist()  # [0] because its the first item in a batch size of 1\n",
    "for pred in preds:\n",
    "    print(string.printable[pred], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IIIT5K.dataset import IIIT5KDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = IIIT5KDataset(split='train')\n",
    "val_set = IIIT5KDataset(split='val')\n",
    "test_set = IIIT5KDataset(split='test')\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JhPgOZMVkw1P"
   },
   "outputs": [],
   "source": [
    "def train_model(model_name: str, num_epochs: int):\n",
    "    model = BaseModel(eow=eow).to(device)\n",
    "    print('Total Parameters:', sum(p.numel() for p in model.parameters()))\n",
    "    print('Trainable Parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=.002)\n",
    "    running_loss = 0.\n",
    "    for epoch in range(num_epochs):\n",
    "        for step, (image, label) in enumerate(train_loader):\n",
    "            image = torch.unsqueeze(image, dim=1).to(device)\n",
    "            label = torch.stack(label, dim=0).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label.T)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10.)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Gather data and report\n",
    "            running_loss += loss.item()\n",
    "        last_loss = running_loss / step # loss per batch\n",
    "        \n",
    "        acc, total = 0., 0.\n",
    "        for o, l in zip(output, label):\n",
    "            o = torch.argmax(o, dim=1)\n",
    "            for o_, l_ in zip(o, l):\n",
    "                if l_ == 100:\n",
    "                    break\n",
    "                if o_ == l_:\n",
    "                    acc += 1.\n",
    "                total += 1.\n",
    "                \n",
    "        acc = acc / total\n",
    "        print(f'epoch {epoch+1} -> train_loss: {last_loss:.4f}, train_acc: {acc:.4f}')\n",
    "\n",
    "        running_loss = 0.\n",
    "\n",
    "        # Validation\n",
    "        val_loss = 0.\n",
    "        val_acc = 0.\n",
    "        val_total = 0.\n",
    "        with torch.no_grad():\n",
    "            for step, (image, label) in enumerate(val_loader):\n",
    "                image = torch.unsqueeze(image, dim=1).to(device)\n",
    "                label = torch.stack(label, dim=0).to(device)\n",
    "\n",
    "                output = model(image)\n",
    "                loss = criterion(output, label.T)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                for o, l in zip(output, label):\n",
    "                    o = torch.argmax(o, dim=1)\n",
    "                    for o_, l_ in zip(o, l):\n",
    "                        if l_ == 100:\n",
    "                            break\n",
    "                        if o_ == l_:\n",
    "                            val_acc += 1.\n",
    "                        val_total += 1.\n",
    "            val_acc = val_acc / val_total\n",
    "            val_loss = val_loss / step\n",
    "            print(f'epoch {epoch+1} -> val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 140792256\n",
      "Trainable Parameters: 140792256\n",
      "epoch 1 -> train_loss: 4.9249, train_acc: 0.0079\n",
      "epoch 1 -> val_loss: 9.2274, val_acc: 0.0090\n",
      "epoch 2 -> train_loss: 4.9179, train_acc: 0.0250\n",
      "epoch 2 -> val_loss: 9.2144, val_acc: 0.0105\n",
      "epoch 3 -> train_loss: 4.9109, train_acc: 0.0198\n",
      "epoch 3 -> val_loss: 9.2015, val_acc: 0.0118\n",
      "epoch 4 -> train_loss: 4.9039, train_acc: 0.0000\n",
      "epoch 4 -> val_loss: 9.1885, val_acc: 0.0096\n",
      "epoch 5 -> train_loss: 4.8969, train_acc: 0.0075\n",
      "epoch 5 -> val_loss: 9.1754, val_acc: 0.0034\n",
      "epoch 6 -> train_loss: 4.8898, train_acc: 0.0183\n",
      "epoch 6 -> val_loss: 9.1622, val_acc: 0.0033\n",
      "epoch 7 -> train_loss: 4.8826, train_acc: 0.0199\n",
      "epoch 7 -> val_loss: 9.1490, val_acc: 0.0097\n",
      "epoch 8 -> train_loss: 4.8755, train_acc: 0.0000\n",
      "epoch 8 -> val_loss: 9.1356, val_acc: 0.0079\n",
      "epoch 9 -> train_loss: 4.8682, train_acc: 0.0000\n",
      "epoch 9 -> val_loss: 9.1221, val_acc: 0.0029\n",
      "epoch 10 -> train_loss: 4.8609, train_acc: 0.0000\n",
      "epoch 10 -> val_loss: 9.1084, val_acc: 0.0141\n",
      "epoch 11 -> train_loss: 4.8535, train_acc: 0.0079\n",
      "epoch 11 -> val_loss: 9.0946, val_acc: 0.0117\n",
      "epoch 12 -> train_loss: 4.8459, train_acc: 0.0000\n",
      "epoch 12 -> val_loss: 9.0805, val_acc: 0.0035\n",
      "epoch 13 -> train_loss: 4.8383, train_acc: 0.0000\n",
      "epoch 13 -> val_loss: 9.0663, val_acc: 0.0114\n",
      "epoch 14 -> train_loss: 4.8305, train_acc: 0.0000\n",
      "epoch 14 -> val_loss: 9.0517, val_acc: 0.0035\n",
      "epoch 15 -> train_loss: 4.8226, train_acc: 0.0186\n",
      "epoch 15 -> val_loss: 9.0369, val_acc: 0.0060\n",
      "epoch 16 -> train_loss: 4.8146, train_acc: 0.0000\n",
      "epoch 16 -> val_loss: 9.0219, val_acc: 0.0105\n",
      "epoch 17 -> train_loss: 4.8064, train_acc: 0.0129\n",
      "epoch 17 -> val_loss: 9.0065, val_acc: 0.0096\n",
      "epoch 18 -> train_loss: 4.7980, train_acc: 0.0000\n",
      "epoch 18 -> val_loss: 8.9908, val_acc: 0.0110\n",
      "epoch 19 -> train_loss: 4.7895, train_acc: 0.0085\n",
      "epoch 19 -> val_loss: 8.9747, val_acc: 0.0039\n",
      "epoch 20 -> train_loss: 4.7807, train_acc: 0.0000\n",
      "epoch 20 -> val_loss: 8.9583, val_acc: 0.0031\n",
      "epoch 21 -> train_loss: 4.7717, train_acc: 0.0087\n",
      "epoch 21 -> val_loss: 8.9414, val_acc: 0.0030\n",
      "epoch 22 -> train_loss: 4.7624, train_acc: 0.0074\n",
      "epoch 22 -> val_loss: 8.9241, val_acc: 0.0115\n",
      "epoch 23 -> train_loss: 4.7530, train_acc: 0.0248\n",
      "epoch 23 -> val_loss: 8.9062, val_acc: 0.0084\n",
      "epoch 24 -> train_loss: 4.7432, train_acc: 0.0068\n",
      "epoch 24 -> val_loss: 8.8879, val_acc: 0.0144\n",
      "epoch 25 -> train_loss: 4.7332, train_acc: 0.0201\n",
      "epoch 25 -> val_loss: 8.8689, val_acc: 0.0235\n",
      "epoch 26 -> train_loss: 4.7227, train_acc: 0.0000\n",
      "epoch 26 -> val_loss: 8.8495, val_acc: 0.0081\n",
      "epoch 27 -> train_loss: 4.7121, train_acc: 0.0255\n",
      "epoch 27 -> val_loss: 8.8294, val_acc: 0.0108\n",
      "epoch 28 -> train_loss: 4.7011, train_acc: 0.0000\n",
      "epoch 28 -> val_loss: 8.8084, val_acc: 0.0103\n",
      "epoch 29 -> train_loss: 4.6897, train_acc: 0.0000\n",
      "epoch 29 -> val_loss: 8.7870, val_acc: 0.0031\n",
      "epoch 30 -> train_loss: 4.6780, train_acc: 0.0073\n",
      "epoch 30 -> val_loss: 8.7648, val_acc: 0.0058\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model_name=\"R2AM\", num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "base_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
