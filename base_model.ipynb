{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cli5G9-3gpLU"
   },
   "source": [
    "# Base Model\n",
    "---\n",
    "This model is taken from the Recursive Recurrent Nets with Attention Modeling for OCR in the Wild paper by Lee et al. In their paper, Lee construct a recursive recurrent neural network with attention modeling. For our project we want to first understand this model architecture, and then try to improve upon it. Later we will provide an ethical analysis for OCR technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ChU11qDfgT7j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import string\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-uVRoffh6k0"
   },
   "source": [
    "From the paper, the base model: \n",
    "> has 8 convolutional layer with 64, 64, 128, 128, 256, 256, 512 and 512 channels, and each convolutional layer uses kernel with a 3 × 3 spatial extent. Convo- lutions are performed with stride 1, zero padding, and ReLU activation function. 2 × 2 max pooling follows the second, fourth, and sixth convolutional layers. The two fully con- nected layers have 4096 units. The input is a resized 32 × 100 gray scale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-s1sWiuuk1tr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax_classes = len(string.printable)\n",
    "print(string.printable)\n",
    "\n",
    "eow = torch.zeros(size=(len(string.printable) + 1,))\n",
    "eow[len(string.printable)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x46pGurygnw7",
    "outputId": "1a9f54eb-73b8-4cd8-8fcd-d0c137334989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "rrrrrrrrrrrrrrrrrrrrrrr"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "from base_model import BaseModel\n",
    "base_cnn_model = BaseModel(eow=eow).to(device)\n",
    "\n",
    "x = torch.zeros(size=(1, 1, 32, 100)).to(device)\n",
    "x = base_cnn_model(x)\n",
    "\n",
    "preds = torch.argmax(x, dim=2).tolist()[0]  # [0] because its the first item in a batch size of 1\n",
    "for pred in preds:\n",
    "    if pred == 100:\n",
    "        break\n",
    "    print(string.printable[pred], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IIIT5K.dataset import IIIT5KDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = IIIT5KDataset(split='train')\n",
    "val_set = IIIT5KDataset(split='val')\n",
    "test_set = IIIT5KDataset(split='test')\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JhPgOZMVkw1P"
   },
   "outputs": [],
   "source": [
    "def train_model(model_name: str, num_epochs: int):\n",
    "    model = BaseModel(eow=eow).to(device)\n",
    "    model.train()\n",
    "    print('Total Parameters:', sum(p.numel() for p in model.parameters()))\n",
    "    print('Trainable Parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.002)\n",
    "    running_loss = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for step, (image, label) in enumerate(train_loader):\n",
    "            image = torch.unsqueeze(image, dim=1).to(device)\n",
    "            label = torch.stack(label, dim=1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Gather data and report\n",
    "            running_loss += loss.item()\n",
    "        last_loss = running_loss / step # loss per batch\n",
    "        print('epoch {} loss: {}'.format(epoch + 1, last_loss))\n",
    "        running_loss = 0.\n",
    "\n",
    "        # Validation\n",
    "        val_loss = 0.\n",
    "        val_acc = 0.\n",
    "        val_total = 0.\n",
    "        with torch.no_grad():\n",
    "            for step, (image, label) in enumerate(val_loader):\n",
    "                image = torch.unsqueeze(image, dim=1).to(device)\n",
    "                label = torch.stack(label, dim=1).to(device)\n",
    "\n",
    "                output = model(image)\n",
    "                loss = criterion(output, label)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                for o, l in zip(output, label):\n",
    "                    o = torch.argmax(o, dim=1)\n",
    "                    l = torch.argmax(l, dim=1)\n",
    "                    for o_, l_ in zip(o, l):\n",
    "                        if o_ == l_:\n",
    "                            val_acc += 1.\n",
    "                        val_total += 1.\n",
    "            print('epoch {} val loss: {}'.format(epoch + 1, val_loss / step))\n",
    "            print('epoch {} val acc: {}'.format(epoch + 1, val_acc / val_total))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 62982693\n",
      "Trainable Parameters: 62982693\n",
      "epoch 1 loss: 0.7616255756066774\n",
      "epoch 1 val loss: 1.4280479213985031\n",
      "epoch 1 val acc: 0.0011304347826086956\n",
      "epoch 2 loss: 0.7616255743540947\n",
      "epoch 2 val loss: 1.4280479193632285\n",
      "epoch 2 val acc: 0.0011304347826086956\n",
      "epoch 3 loss: 0.761625574093816\n",
      "epoch 3 val loss: 1.428047919400566\n",
      "epoch 3 val acc: 0.0011304347826086956\n",
      "epoch 4 loss: 0.7616255735439978\n",
      "epoch 4 val loss: 1.4280479161658035\n",
      "epoch 4 val acc: 0.0011304347826086956\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13866/1320314150.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"R2AM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_13866/3420040454.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_name, num_epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Gather data and report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mlast_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;31m# loss per batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch {} loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_model(model_name=\"R2AM\", num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "base_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
